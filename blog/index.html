<!DOCTYPE html>
<html lang="en">
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="data blog">
  <meta name="author" content="michael burt">
  <link rel="shortcut icon" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css">

  <title>michael's blog</title>

  <!-- Bootstrap core CSS -->
  <link href="http://maxcdn.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="http://mpburt.com/css/style-blog.css" rel="stylesheet">

  <!--[if lt IE 9]>
    <script src="../../assets/js/ie8-responsive-file-warning.js"></script>
  <![endif]-->

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->

  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

</head>

  <body>

    <div class="blog-masthead">
      <div class="container">
        <nav class="blog-nav">
          <a class="blog-nav-item" href="/">Home</a>
          <a class="blog-nav-item" href="/about/">About</a>
          <a class="blog-nav-item active" href="/blog/">Blog</a>
          <a class="blog-nav-item" href="/life/">Life</a>
        </nav>
      </div>
    </div>

  <div class="container">

  <div class="blog-header">
    <h3 class="blog-title">PJM 5 Minute Data</h3>
  </div>

  <div class="row">

    <div class="col-sm-8 blog-main">

      <div class="blog-post">

        <p class="blog-post-meta">November 29, 2017 by <a href="/">michael</a></p>

        <p>This page describes how to collect a few different types of 5 minute data from <a href="http://www.pjm.com/">PJM Interconnection</a>. The code is pretty straightforward and it available in a git repository, located here.</p>

        <h3>The Data</h3>

        <p>I am collecting the data from the old-school <a href="http://oasis.pjm.com/system.htm">PJM operations page</a>. This site includes several types of data: 500kV bus LMP's (<a href="https://pjm.com/~/media/about-pjm/newsroom/fact-sheets/locational-marginal-pricing-fact-sheet.ashx">locational marginal price</a>), <a href="http://www.pjm.com/markets-and-operations/energy/lmp-model-info/fwaad.aspx">aggregate</a> LMP's, loads, and RTI flows.
        
        This page really looks like it is powered by a dusty server in a closet somewhere, but it works.</p>

        <br>

        <h4><strong>The script</strong></h4>

        <p>The collector script is written in Python. By default, the script inserts the data into a database, but I am also including the ability to output a CSV file. To output a csv, just execute the script with a -csv command.
        
        I am collecting and storing the data with regular a datetime values so that it is more user friendly. I usually try to convert datetimes to GMT for timezone and DST conversions. Electricity markets are pretty painful when it comes to effectively handling datetimes (HE anybody?).
      
        I am using a package called BeautifulSoup to scrape this data. BeautifulSoup might be a bit heavy for this use case, but it is easy to use. You could easily do task without anything fancy like BeautifulSoup though.</p>

        <pre><code>sudo apt-get update -y &amp;&amp; sudo apt-get upgrade -y</code></pre>

        <p>Next, install MySQL along with the Python connector which we will use later.</p>

        <pre><code>sudo apt-get install mysql-server python-mysqldb -y</code></pre>

        <p>During installation, you will be asked to enter a password for the 
        <strong>root</strong> user.
        </p>

        <p>After you have installed MySQL, fire it up on the RPi by entering the following:</p>
        
        <pre><code>mysql -u root -p</code></pre>

        <p>The <strong>-u</strong> argument specifies the <strong>user</strong> and the 
        <strong>-p</strong> argument tells mysql to ask for a password.</p>

        <br>

        <h4><strong>Creating a database and user</strong></h4>
  
        <p>Now let's create the database that will store all of our data:</p>
  
        <pre><code>mysql&gt;CREATE DATABASE rtpjmprices
  DEFAULT CHARACTER SET utf8
  DEFAULT COLLATE utf8_general_ci;</code></pre>
    
        <p>We want to create a user named <strong>parser</strong> which will connect to the 
        <strong>rtpjmprices</strong> database and populate it with data.</p>
        
        <pre><code>mysql&gt;CREATE USER 'parser'@'localhost';</code></pre>
        
        <p>This user will have to have the correct permissions to write to the database.</p>
        
        <pre><code>mysql&gt;GRANT ALL PRIVILEGES ON rtpjmprices.*
  TO 'parser'@'localhost';</code></pre>

        <br>
          
        <h4><strong>Creating the tables</strong></h4>

        <p>Now we will create two tables, one table to store the price data (<strong>prices
        </strong>) and one table to store the name of the price node (<strong>price_nodes
        </strong>).</p>

        <p>For <strong>price_nodes</strong>, we are going to create two columns, a primary 
        key column (<strong>price_node_id</strong>) and a name column (<strong>name
        </strong>):</p>

        <pre><code>mysql&gt;CREATE TABLE `price_nodes` (
  `price_node_id` INT NOT NULL AUTO_INCREMENT,
  `name` VARCHAR(10) NOT NULL ,
  PRIMARY KEY (`price_node_id`) ) ENGINE=InnoDB;</code></pre>

        <p>For our <strong>prices</strong>, we are going to need a few more columns. We need 
        a primary key column, a <strong>price_node_id</strong> column (since we will be 
        bringing in data from multiple markets), a price column, and a eventdatetime column:</p>

        <pre><code>mysql&gt;CREATE TABLE `prices` (
  `price_id` INT NOT NULL AUTO_INCREMENT,
  `price_node_id` VARCHAR(10) NOT NULL ,
  `price` DECIMAL(6,2) NOT NULL ,
  `datetime` DATETIME NOT NULL ,
  PRIMARY KEY (`price_id`) ) ENGINE=InnoDB;</code></pre>

        <p>The last step in setting up our database it creating a relation between our 
        tables by applying a foreign key constraint on <strong>prices.price_node_id</strong>
        . We will also add an index to make the database a little more performant. To do 
        this, execute the following in the MySQL console:</p>

        <pre><code>mysql&gt;ALTER TABLE `prices` 
  ADD CONSTRAINT `price_node_id`
  FOREIGN KEY (`price_node_id`)
  REFERENCES `price_nodes` (`price_node_id`)
  ON DELETE CASCADE
  ON UPDATE CASCADE
  , ADD INDEX `price_id_idx` (`price_id` ASC);</code></pre>

        <p>Drop all of those scripts into a file and call it <strong>schema.sql</strong>. 
        This will allow us to easily deploy the database to a new server if/when we need to. 
        It is also just a good habit to get into. </p>

        <p>Feel free to download my version from here.</p> 

        <p>We are now ready to write the script that will populate our database with data.</p>

        <hr><h3>The Parser</h3>

        <p>We are going to write a parser in Python using the 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> 
        package. We are going to harvest our data from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">this website</a>. PJM 
        updates the prices on this page every five minutes. For now, let's just focus on 
        harvesting the "Zone" prices. Zones can be thought of as subsections of the greater 
        PJM system.</p>

        <br>

        <h4><strong>Installing Python and required packages</strong></h4>

        <p>The first step is installing Python and required packages. We are going to 
          install <strong>python-dev</strong> since it also comes with <strong>vitualenv
        </strong> and <strong>pip</strong>, along with some other packages:</p>

        <pre><code>sudo apt-get install python-pip build-essential python-dev libmysqlclient-dev -y</code></pre>

        <p>Now we are going to write the parser that will harvest the prices from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">here</a>. First, I 
        suggest reading a a little bit about BeautifulSoup. The 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">documentation</a> 
        is pretty fantastic.</p>

        <p>Let's install the packages that we will be using with <strong>pip</strong>:</p>

        <pre><code>sudo pip install beautifulsoup4 && pip install numpy && pip install MySQL-python</code></pre>

        <p>Now let's create a folder for our application:</p>
        <pre><code>mkdir ~/pjm_app && cd ~/pjm_app</code></pre>

        <p>Create an empty file called <strong>parser.py</strong> where we will put our code 
        to grab the prices from PJM.</p>

        <pre><code>touch ~/pjm_app/parser.py</code></pre>

        <p>Since we have created our application folder, let's put our <strong>schema.sql
        </strong> file in there as well. You can copy the code from the GitHub and paste it 
        into you file.</p>
        
        <pre><code>touch ~/pjm_app/schema.sql
  sudo nano ~/pjm_app/schema.sql</code></pre>

        <p>Once nano has opened, paste in the code from here and hit <strong>ctrl x</strong> 
        to save and close. At this point, our application should look like:</p>
        <pre><code>..
└── pjm_app
├── parser.py
└── schema.sql</code></pre>
              
        <p>I am not going to walk you through exactly how to write the Python parser, but you 
        can grab the code from here and paste it into <strong>parser.py</strong> using nano. 
        If you have questions about specific sections of the code, please feel free to comment 
        on this post. I have commented the code very well so you should be able to glean what 
        is going on from there, hopefully...</p>
        
        <br>
        <br>
      </div>

      <div class="blog-post">

        <a name="20130927"><h3>Electricity Price Web App - Part 1 - Backend</h3></a>

        <p class="blog-post-meta">September 27, 2013 by <a href="/">michael</a></p>

        <p>This tutorial describes how to build a web app that displays the price of 
        electricity in <a href="http://www.pjm.com/">PJM Interconnection</a>. This 
        tutorial is broken up into three parts:</p>

        <ul>
          <li><a href="/blog/data/#20140424">Part 1 - Backend - write database and 
          parser</a></li>
          <li><a href="/blog/data/#20140627">Part 2 - Middile Layer - extract the data 
          and send to the front end</a></li>
          <li><a href="/blog/data/#20140627">Part 3 - Visualization - visualize the data 
          using R and Shiny</a></li>
        </ul>
  
        <p>All of these posts assumes that you have rudimentary knowledge of a few 
        things:</p>

        <ul>
          <li>Unix operating system</li>
          <li>Python</li>
          <li>SQL</li>
          <li>R</li>
        </ul>

        <p>With some understanding of the above technologies, you will be able to build a 
        web app that allows you to visualize a timeseries of the real-time price of 
        energy in PJM.</p>

        <hr>

        <h3>The Database</h3>

        <p>The first step to deploying this web app is setting up a database to store the 
        data we will be visualizing. We will use MySQL because it is very user friendly, 
        free, and powerful enough to meet our needs.</p>

        <br>

        <h4><strong>Installing MySQL in Ubuntu</strong></h4>

        <p>Installing MySQL is very simple. Before we go any further, it is a good idea to 
        make sure everything is up-to-date by entering the following (the <strong>-y</strong> 
        argument tells bash to automatically select "yes" when prompted):</p>

        <pre><code>sudo apt-get update -y &amp;&amp; sudo apt-get upgrade -y</code></pre>

        <p>Next, install MySQL along with the Python connector which we will use later.</p>

        <pre><code>sudo apt-get install mysql-server python-mysqldb -y</code></pre>

        <p>During installation, you will be asked to enter a password for the 
        <strong>root</strong> user.
        </p>

        <p>After you have installed MySQL, fire it up on the RPi by entering the following:</p>
        
        <pre><code>mysql -u root -p</code></pre>

        <p>The <strong>-u</strong> argument specifies the <strong>user</strong> and the 
        <strong>-p</strong> argument tells mysql to ask for a password.</p>

        <br>

        <h4><strong>Creating a database and user</strong></h4>
  
        <p>Now let's create the database that will store all of our data:</p>
  
        <pre><code>mysql&gt;CREATE DATABASE rtpjmprices
  DEFAULT CHARACTER SET utf8
  DEFAULT COLLATE utf8_general_ci;</code></pre>
    
        <p>We want to create a user named <strong>parser</strong> which will connect to the 
        <strong>rtpjmprices</strong> database and populate it with data.</p>
        
        <pre><code>mysql&gt;CREATE USER 'parser'@'localhost';</code></pre>
        
        <p>This user will have to have the correct permissions to write to the database.</p>
        
        <pre><code>mysql&gt;GRANT ALL PRIVILEGES ON rtpjmprices.*
  TO 'parser'@'localhost';</code></pre>

        <br>
          
        <h4><strong>Creating the tables</strong></h4>

        <p>Now we will create two tables, one table to store the price data (<strong>prices
        </strong>) and one table to store the name of the price node (<strong>price_nodes
        </strong>).</p>

        <p>For <strong>price_nodes</strong>, we are going to create two columns, a primary 
        key column (<strong>price_node_id</strong>) and a name column (<strong>name
        </strong>):</p>

        <pre><code>mysql&gt;CREATE TABLE `price_nodes` (
  `price_node_id` INT NOT NULL AUTO_INCREMENT,
  `name` VARCHAR(10) NOT NULL ,
  PRIMARY KEY (`price_node_id`) ) ENGINE=InnoDB;</code></pre>

        <p>For our <strong>prices</strong>, we are going to need a few more columns. We need 
        a primary key column, a <strong>price_node_id</strong> column (since we will be 
        bringing in data from multiple markets), a price column, and a eventdatetime column:</p>

        <pre><code>mysql&gt;CREATE TABLE `prices` (
  `price_id` INT NOT NULL AUTO_INCREMENT,
  `price_node_id` VARCHAR(10) NOT NULL ,
  `price` DECIMAL(6,2) NOT NULL ,
  `datetime` DATETIME NOT NULL ,
  PRIMARY KEY (`price_id`) ) ENGINE=InnoDB;</code></pre>

        <p>The last step in setting up our database it creating a relation between our 
        tables by applying a foreign key constraint on <strong>prices.price_node_id</strong>
        . We will also add an index to make the database a little more performant. To do 
        this, execute the following in the MySQL console:</p>

        <pre><code>mysql&gt;ALTER TABLE `prices` 
  ADD CONSTRAINT `price_node_id`
  FOREIGN KEY (`price_node_id`)
  REFERENCES `price_nodes` (`price_node_id`)
  ON DELETE CASCADE
  ON UPDATE CASCADE
  , ADD INDEX `price_id_idx` (`price_id` ASC);</code></pre>

        <p>Drop all of those scripts into a file and call it <strong>schema.sql</strong>. 
        This will allow us to easily deploy the database to a new server if/when we need to. 
        It is also just a good habit to get into. </p>

        <p>Feel free to download my version from here.</p> 

        <p>We are now ready to write the script that will populate our database with data.</p>

        <hr><h3>The Parser</h3>

        <p>We are going to write a parser in Python using the 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> 
        package. We are going to harvest our data from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">this website</a>. PJM 
        updates the prices on this page every five minutes. For now, let's just focus on 
        harvesting the "Zone" prices. Zones can be thought of as subsections of the greater 
        PJM system.</p>

        <br>

        <h4><strong>Installing Python and required packages</strong></h4>

        <p>The first step is installing Python and required packages. We are going to 
          install <strong>python-dev</strong> since it also comes with <strong>vitualenv
        </strong> and <strong>pip</strong>, along with some other packages:</p>

        <pre><code>sudo apt-get install python-pip build-essential python-dev libmysqlclient-dev -y</code></pre>

        <p>Now we are going to write the parser that will harvest the prices from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">here</a>. First, I 
        suggest reading a a little bit about BeautifulSoup. The 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">documentation</a> 
        is pretty fantastic.</p>

        <p>Let's install the packages that we will be using with <strong>pip</strong>:</p>

        <pre><code>sudo pip install beautifulsoup4 && pip install numpy && pip install MySQL-python</code></pre>

        <p>Now let's create a folder for our application:</p>
        <pre><code>mkdir ~/pjm_app && cd ~/pjm_app</code></pre>

        <p>Create an empty file called <strong>parser.py</strong> where we will put our code 
        to grab the prices from PJM.</p>

        <pre><code>touch ~/pjm_app/parser.py</code></pre>

        <p>Since we have created our application folder, let's put our <strong>schema.sql
        </strong> file in there as well. You can copy the code from the GitHub and paste it 
        into you file.</p>
        
        <pre><code>touch ~/pjm_app/schema.sql
  sudo nano ~/pjm_app/schema.sql</code></pre>

        <p>Once nano has opened, paste in the code from here and hit <strong>ctrl x</strong> 
        to save and close. At this point, our application should look like:</p>
        <pre><code>..
└── pjm_app
├── parser.py
└── schema.sql</code></pre>
              
        <p>I am not going to walk you through exactly how to write the Python parser, but you 
        can grab the code from here and paste it into <strong>parser.py</strong> using nano. 
        If you have questions about specific sections of the code, please feel free to comment 
        on this post. I have commented the code very well so you should be able to glean what 
        is going on from there, hopefully...</p>
        
      </div>

      <br>
      <br>

      <div class="blog-post">

        <a name="20130927"><h3>Electricity Price Web App - Part 1 - Backend</h3></a>

        <p class="blog-post-meta">September 27, 2013 by <a href="/">michael</a></p>

        <p>This tutorial describes how to build a web app that displays the price of 
        electricity in <a href="http://www.pjm.com/">PJM Interconnection</a>. This 
        tutorial is broken up into three parts:</p>

        <ul>
          <li><a href="/blog/data/#20140424">Part 1 - Backend - write database and 
          parser</a></li>
          <li><a href="/blog/data/#20140627">Part 2 - Middile Layer - extract the data 
          and send to the front end</a></li>
          <li><a href="/blog/data/#20140627">Part 3 - Visualization - visualize the data 
          using R and Shiny</a></li>
        </ul>
  
        <p>All of these posts assumes that you have rudimentary knowledge of a few 
        things:</p>

        <ul>
          <li>Unix operating system</li>
          <li>Python</li>
          <li>SQL</li>
          <li>R</li>
        </ul>

        <p>With some understanding of the above technologies, you will be able to build a 
        web app that allows you to visualize a timeseries of the real-time price of 
        energy in PJM.</p>

        <hr>

        <h3>The Database</h3>

        <p>The first step to deploying this web app is setting up a database to store the 
        data we will be visualizing. We will use MySQL because it is very user friendly, 
        free, and powerful enough to meet our needs.</p>

        <br>

        <h4><strong>Installing MySQL in Ubuntu</strong></h4>

        <p>Installing MySQL is very simple. Before we go any further, it is a good idea to 
        make sure everything is up-to-date by entering the following (the <strong>-y</strong> 
        argument tells bash to automatically select "yes" when prompted):</p>

        <pre><code>sudo apt-get update -y &amp;&amp; sudo apt-get upgrade -y</code></pre>

        <p>Next, install MySQL along with the Python connector which we will use later.</p>

        <pre><code>sudo apt-get install mysql-server python-mysqldb -y</code></pre>

        <p>During installation, you will be asked to enter a password for the 
        <strong>root</strong> user.
        </p>

        <p>After you have installed MySQL, fire it up on the RPi by entering the following:</p>
        
        <pre><code>mysql -u root -p</code></pre>

        <p>The <strong>-u</strong> argument specifies the <strong>user</strong> and the 
        <strong>-p</strong> argument tells mysql to ask for a password.</p>

        <br>

        <h4><strong>Creating a database and user</strong></h4>
  
        <p>Now let's create the database that will store all of our data:</p>
  
        <pre><code>mysql&gt;CREATE DATABASE rtpjmprices
  DEFAULT CHARACTER SET utf8
  DEFAULT COLLATE utf8_general_ci;</code></pre>
    
        <p>We want to create a user named <strong>parser</strong> which will connect to the 
        <strong>rtpjmprices</strong> database and populate it with data.</p>
        
        <pre><code>mysql&gt;CREATE USER 'parser'@'localhost';</code></pre>
        
        <p>This user will have to have the correct permissions to write to the database.</p>
        
        <pre><code>mysql&gt;GRANT ALL PRIVILEGES ON rtpjmprices.*
  TO 'parser'@'localhost';</code></pre>

        <br>
          
        <h4><strong>Creating the tables</strong></h4>

        <p>Now we will create two tables, one table to store the price data (<strong>prices
        </strong>) and one table to store the name of the price node (<strong>price_nodes
        </strong>).</p>

        <p>For <strong>price_nodes</strong>, we are going to create two columns, a primary 
        key column (<strong>price_node_id</strong>) and a name column (<strong>name
        </strong>):</p>

        <pre><code>mysql&gt;CREATE TABLE `price_nodes` (
  `price_node_id` INT NOT NULL AUTO_INCREMENT,
  `name` VARCHAR(10) NOT NULL ,
  PRIMARY KEY (`price_node_id`) ) ENGINE=InnoDB;</code></pre>

        <p>For our <strong>prices</strong>, we are going to need a few more columns. We need 
        a primary key column, a <strong>price_node_id</strong> column (since we will be 
        bringing in data from multiple markets), a price column, and a eventdatetime column:</p>

        <pre><code>mysql&gt;CREATE TABLE `prices` (
  `price_id` INT NOT NULL AUTO_INCREMENT,
  `price_node_id` VARCHAR(10) NOT NULL ,
  `price` DECIMAL(6,2) NOT NULL ,
  `datetime` DATETIME NOT NULL ,
  PRIMARY KEY (`price_id`) ) ENGINE=InnoDB;</code></pre>

        <p>The last step in setting up our database it creating a relation between our 
        tables by applying a foreign key constraint on <strong>prices.price_node_id</strong>
        . We will also add an index to make the database a little more performant. To do 
        this, execute the following in the MySQL console:</p>

        <pre><code>mysql&gt;ALTER TABLE `prices` 
  ADD CONSTRAINT `price_node_id`
  FOREIGN KEY (`price_node_id`)
  REFERENCES `price_nodes` (`price_node_id`)
  ON DELETE CASCADE
  ON UPDATE CASCADE
  , ADD INDEX `price_id_idx` (`price_id` ASC);</code></pre>

        <p>Drop all of those scripts into a file and call it <strong>schema.sql</strong>. 
        This will allow us to easily deploy the database to a new server if/when we need to. 
        It is also just a good habit to get into. </p>

        <p>Feel free to download my version from here.</p> 

        <p>We are now ready to write the script that will populate our database with data.</p>

        <hr><h3>The Parser</h3>

        <p>We are going to write a parser in Python using the 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> 
        package. We are going to harvest our data from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">this website</a>. PJM 
        updates the prices on this page every five minutes. For now, let's just focus on 
        harvesting the "Zone" prices. Zones can be thought of as subsections of the greater 
        PJM system.</p>

        <br>

        <h4><strong>Installing Python and required packages</strong></h4>

        <p>The first step is installing Python and required packages. We are going to 
          install <strong>python-dev</strong> since it also comes with <strong>vitualenv
        </strong> and <strong>pip</strong>, along with some other packages:</p>

        <pre><code>sudo apt-get install python-pip build-essential python-dev libmysqlclient-dev -y</code></pre>

        <p>Now we are going to write the parser that will harvest the prices from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">here</a>. First, I 
        suggest reading a a little bit about BeautifulSoup. The 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">documentation</a> 
        is pretty fantastic.</p>

        <p>Let's install the packages that we will be using with <strong>pip</strong>:</p>

        <pre><code>sudo pip install beautifulsoup4 && pip install numpy && pip install MySQL-python</code></pre>

        <p>Now let's create a folder for our application:</p>
        <pre><code>mkdir ~/pjm_app && cd ~/pjm_app</code></pre>

        <p>Create an empty file called <strong>parser.py</strong> where we will put our code 
        to grab the prices from PJM.</p>

        <pre><code>touch ~/pjm_app/parser.py</code></pre>

        <p>Since we have created our application folder, let's put our <strong>schema.sql
        </strong> file in there as well. You can copy the code from the GitHub and paste it 
        into you file.</p>
        
        <pre><code>touch ~/pjm_app/schema.sql
  sudo nano ~/pjm_app/schema.sql</code></pre>

        <p>Once nano has opened, paste in the code from here and hit <strong>ctrl x</strong> 
        to save and close. At this point, our application should look like:</p>
        <pre><code>..
└── pjm_app
├── parser.py
└── schema.sql</code></pre>
              
        <p>I am not going to walk you through exactly how to write the Python parser, but you 
        can grab the code from here and paste it into <strong>parser.py</strong> using nano. 
        If you have questions about specific sections of the code, please feel free to comment 
        on this post. I have commented the code very well so you should be able to glean what 
        is going on from there, hopefully...</p>
        
        <br>
        <br>
      </div>

      <div class="blog-post">

        <a name="20130927"><h3>Electricity Price Web App - Part 1 - Backend</h3></a>

        <p class="blog-post-meta">September 27, 2013 by <a href="/">michael</a></p>

        <p>This tutorial describes how to build a web app that displays the price of 
        electricity in <a href="http://www.pjm.com/">PJM Interconnection</a>. This 
        tutorial is broken up into three parts:</p>

        <ul>
          <li><a href="/blog/data/#20140424">Part 1 - Backend - write database and 
          parser</a></li>
          <li><a href="/blog/data/#20140627">Part 2 - Middile Layer - extract the data 
          and send to the front end</a></li>
          <li><a href="/blog/data/#20140627">Part 3 - Visualization - visualize the data 
          using R and Shiny</a></li>
        </ul>
  
        <p>All of these posts assumes that you have rudimentary knowledge of a few 
        things:</p>

        <ul>
          <li>Unix operating system</li>
          <li>Python</li>
          <li>SQL</li>
          <li>R</li>
        </ul>

        <p>With some understanding of the above technologies, you will be able to build a 
        web app that allows you to visualize a timeseries of the real-time price of 
        energy in PJM.</p>

        <hr>

        <h3>The Database</h3>

        <p>The first step to deploying this web app is setting up a database to store the 
        data we will be visualizing. We will use MySQL because it is very user friendly, 
        free, and powerful enough to meet our needs.</p>

        <br>

        <h4><strong>Installing MySQL in Ubuntu</strong></h4>

        <p>Installing MySQL is very simple. Before we go any further, it is a good idea to 
        make sure everything is up-to-date by entering the following (the <strong>-y</strong> 
        argument tells bash to automatically select "yes" when prompted):</p>

        <pre><code>sudo apt-get update -y &amp;&amp; sudo apt-get upgrade -y</code></pre>

        <p>Next, install MySQL along with the Python connector which we will use later.</p>

        <pre><code>sudo apt-get install mysql-server python-mysqldb -y</code></pre>

        <p>During installation, you will be asked to enter a password for the 
        <strong>root</strong> user.
        </p>

        <p>After you have installed MySQL, fire it up on the RPi by entering the following:</p>
        
        <pre><code>mysql -u root -p</code></pre>

        <p>The <strong>-u</strong> argument specifies the <strong>user</strong> and the 
        <strong>-p</strong> argument tells mysql to ask for a password.</p>

        <br>

        <h4><strong>Creating a database and user</strong></h4>
  
        <p>Now let's create the database that will store all of our data:</p>
  
        <pre><code>mysql&gt;CREATE DATABASE rtpjmprices
  DEFAULT CHARACTER SET utf8
  DEFAULT COLLATE utf8_general_ci;</code></pre>
    
        <p>We want to create a user named <strong>parser</strong> which will connect to the 
        <strong>rtpjmprices</strong> database and populate it with data.</p>
        
        <pre><code>mysql&gt;CREATE USER 'parser'@'localhost';</code></pre>
        
        <p>This user will have to have the correct permissions to write to the database.</p>
        
        <pre><code>mysql&gt;GRANT ALL PRIVILEGES ON rtpjmprices.*
  TO 'parser'@'localhost';</code></pre>

        <br>
          
        <h4><strong>Creating the tables</strong></h4>

        <p>Now we will create two tables, one table to store the price data (<strong>prices
        </strong>) and one table to store the name of the price node (<strong>price_nodes
        </strong>).</p>

        <p>For <strong>price_nodes</strong>, we are going to create two columns, a primary 
        key column (<strong>price_node_id</strong>) and a name column (<strong>name
        </strong>):</p>

        <pre><code>mysql&gt;CREATE TABLE `price_nodes` (
  `price_node_id` INT NOT NULL AUTO_INCREMENT,
  `name` VARCHAR(10) NOT NULL ,
  PRIMARY KEY (`price_node_id`) ) ENGINE=InnoDB;</code></pre>

        <p>For our <strong>prices</strong>, we are going to need a few more columns. We need 
        a primary key column, a <strong>price_node_id</strong> column (since we will be 
        bringing in data from multiple markets), a price column, and a eventdatetime column:</p>

        <pre><code>mysql&gt;CREATE TABLE `prices` (
  `price_id` INT NOT NULL AUTO_INCREMENT,
  `price_node_id` VARCHAR(10) NOT NULL ,
  `price` DECIMAL(6,2) NOT NULL ,
  `datetime` DATETIME NOT NULL ,
  PRIMARY KEY (`price_id`) ) ENGINE=InnoDB;</code></pre>

        <p>The last step in setting up our database it creating a relation between our 
        tables by applying a foreign key constraint on <strong>prices.price_node_id</strong>
        . We will also add an index to make the database a little more performant. To do 
        this, execute the following in the MySQL console:</p>

        <pre><code>mysql&gt;ALTER TABLE `prices` 
  ADD CONSTRAINT `price_node_id`
  FOREIGN KEY (`price_node_id`)
  REFERENCES `price_nodes` (`price_node_id`)
  ON DELETE CASCADE
  ON UPDATE CASCADE
  , ADD INDEX `price_id_idx` (`price_id` ASC);</code></pre>

        <p>Drop all of those scripts into a file and call it <strong>schema.sql</strong>. 
        This will allow us to easily deploy the database to a new server if/when we need to. 
        It is also just a good habit to get into. </p>

        <p>Feel free to download my version from here.</p> 

        <p>We are now ready to write the script that will populate our database with data.</p>

        <hr><h3>The Parser</h3>

        <p>We are going to write a parser in Python using the 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> 
        package. We are going to harvest our data from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">this website</a>. PJM 
        updates the prices on this page every five minutes. For now, let's just focus on 
        harvesting the "Zone" prices. Zones can be thought of as subsections of the greater 
        PJM system.</p>

        <br>

        <h4><strong>Installing Python and required packages</strong></h4>

        <p>The first step is installing Python and required packages. We are going to 
          install <strong>python-dev</strong> since it also comes with <strong>vitualenv
        </strong> and <strong>pip</strong>, along with some other packages:</p>

        <pre><code>sudo apt-get install python-pip build-essential python-dev libmysqlclient-dev -y</code></pre>

        <p>Now we are going to write the parser that will harvest the prices from 
        <a href="http://www.pjm.com/pub/account/lmpgen/lmppost.html">here</a>. First, I 
        suggest reading a a little bit about BeautifulSoup. The 
        <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">documentation</a> 
        is pretty fantastic.</p>

        <p>Let's install the packages that we will be using with <strong>pip</strong>:</p>

        <pre><code>sudo pip install beautifulsoup4 && pip install numpy && pip install MySQL-python</code></pre>

        <p>Now let's create a folder for our application:</p>
        <pre><code>mkdir ~/pjm_app && cd ~/pjm_app</code></pre>

        <p>Create an empty file called <strong>parser.py</strong> where we will put our code 
        to grab the prices from PJM.</p>

        <pre><code>touch ~/pjm_app/parser.py</code></pre>

        <p>Since we have created our application folder, let's put our <strong>schema.sql
        </strong> file in there as well. You can copy the code from the GitHub and paste it 
        into you file.</p>
        
        <pre><code>touch ~/pjm_app/schema.sql
  sudo nano ~/pjm_app/schema.sql</code></pre>

        <p>Once nano has opened, paste in the code from here and hit <strong>ctrl x</strong> 
        to save and close. At this point, our application should look like:</p>
        <pre><code>..
└── pjm_app
├── parser.py
└── schema.sql</code></pre>
              
        <p>I am not going to walk you through exactly how to write the Python parser, but you 
        can grab the code from here and paste it into <strong>parser.py</strong> using nano. 
        If you have questions about specific sections of the code, please feel free to comment 
        on this post. I have commented the code very well so you should be able to glean what 
        is going on from there, hopefully...</p>
        
      </div>


    </div><!-- /.blog-main -->

    <div class="col-sm-3 col-sm-offset-1 blog-sidebar">

      <div class="sidebar-module sidebar-module-inset">
        <h4><strong>About</strong></h4>
          <p><h5>This is my blog where I catalog projects that I work on in my free 
          time.</p>

          <p>I am always open to suggestions on how to improve the projects I have 
          written up.</h5></p>
      </div>

      <div class="sidebar-module sidebar-module-inset">
        <h4><strong>Archives</strong></h4>
        <ol class="list-unstyled">
          <h5>
            <li><a href="#20130927">PJM Web App - Part 1 - Backend</a></li>
            <li><a href="#20140424">PJM Web App - Part 2 - Viz.</a></li>
            <li><br></li>
            <li><a href="http://mpburt.com/blog/data/#20140424">Optimal Portfolio Calculator</a></li>
            <li><a href="http://mpburt.com/blog/data/#20140424">MHA Bakken Oil Production</a></li>
          </h5>
        </ol>
      </div>

      <hr>
      <center>
        <a href="https://www.linkedin.com/pub/michael-burt/1a/b98/807"><img src="http://mpburt.com/img/linkedin.svg" width="50px" hspace="7"></a>
        <a href="mailto:michaelpburt@gmail.com?Subject=Hello!" target="_top"><img src="http://mpburt.com/img/email.svg" width="50px" hspace="7"></a>
          <a href="https://twitter.com/michaei"><img src="http://mpburt.com/img/twitter.svg" width="50px" hspace="7"></a>
      </center>

      </div><!-- /.blog-sidebar -->

    </div><!-- /.row -->

  </div><!-- /.container -->

  <div class="blog-footer">
    <p><a href="http://mpburt.com/blog/#">Back to top</a></p>

    <br>

    <center>
      <a href="https://www.linkedin.com/pub/michael-burt/1a/b98/807"><img src="http://mpburt.com/img/linkedin.svg" width="50px" hspace="7"></a>
      <a href="mailto:michaelpburt@gmail.com?Subject=Hello!" target="_top"><img src="http://mpburt.com/img/email.svg" width="50px" hspace="7"></a>
      <a href="https://twitter.com/michaei"><img src="http://mpburt.com/img/twitter.svg" width="50px" hspace="7"></a>
    </center>

  </div>

  <!-- Bootstrap core JavaScript
  ================================================== -->
  <!-- Placed at the end of the document so the pages load faster -->
  <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
  <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css"></script>
  
</body>

</html>